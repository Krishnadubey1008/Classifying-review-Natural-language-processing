{"cells":[{"cell_type":"markdown","metadata":{"colab_type":"text","id":"VwK5-9FIB-lu"},"source":["# Natural Language Processing"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"Qekztq71CixT"},"source":["## Cleaning the texts"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":52},"colab_type":"code","executionInfo":{"elapsed":1977,"status":"ok","timestamp":1589837794372,"user":{"displayName":"Hadelin de Ponteves","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhEuXdT7eQweUmRPW8_laJuPggSK6hfvpl5a6WBaA=s64","userId":"15047218817161520419"},"user_tz":-240},"id":"8u_yXh9dCmEE","outputId":"bdcb9868-74c8-40b2-e5e9-877b949ce385"},"outputs":[{"name":"stdout","output_type":"stream","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n"]}],"source":["import re\n","import nltk\n","nltk.download('stopwords')\n","from nltk.corpus import stopwords\n","from nltk.stem.porter import PorterStemmer\n","corpus = []\n","for i in range(0, 1000):\n","  review = re.sub('[^a-zA-Z]', ' ', dataset['Review'][i])\n","  review = review.lower()\n","  review = review.split()\n","  ps = PorterStemmer()\n","  all_stopwords = stopwords.words('english')\n","  all_stopwords.remove('not')\n","  review = [ps.stem(word) for word in review if not word in set(all_stopwords)]\n","  review = ' '.join(review)\n","  corpus.append(review)"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"CLqmAkANCp1-"},"source":["## Creating the Bag of Words model"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{},"colab_type":"code","id":"qroF7XcSCvY3"},"outputs":[],"source":["from sklearn.feature_extraction.text import CountVectorizer\n","cv = CountVectorizer(max_features = 1500)\n","X = cv.fit_transform(corpus).toarray()\n","y = dataset.iloc[:, -1].values"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"DH_VjgPzC2cd"},"source":["## Splitting the dataset into the Training set and Test set"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{},"colab_type":"code","id":"qQXYM5VzDDDI"},"outputs":[],"source":["from sklearn.model_selection import train_test_split\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = 0)"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"VkIq23vEDIPt"},"source":["## Training the Naive Bayes model on the Training set"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":34},"colab_type":"code","executionInfo":{"elapsed":4465,"status":"ok","timestamp":1589791461906,"user":{"displayName":"Hadelin de Ponteves","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhEuXdT7eQweUmRPW8_laJuPggSK6hfvpl5a6WBaA=s64","userId":"15047218817161520419"},"user_tz":-240},"id":"DS9oiDXXDRdI","outputId":"77513c39-0ec6-4544-c056-26abe055b746"},"outputs":[{"data":{"text/plain":["GaussianNB(priors=None, var_smoothing=1e-09)"]},"execution_count":6,"metadata":{"tags":[]},"output_type":"execute_result"}],"source":["from sklearn.naive_bayes import GaussianNB\n","classifier = GaussianNB()\n","classifier.fit(X_train, y_train)"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyMx/KsxUDrn2M5QbIb03B9p","collapsed_sections":[],"name":"natural_language_processing.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"}},"nbformat":4,"nbformat_minor":0}
